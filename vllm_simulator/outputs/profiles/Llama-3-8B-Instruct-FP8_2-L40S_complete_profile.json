{
    "block_size": 16,
    "cuda_profile": {
        "block_size": 16,
        "input_token_upper_limit": 1003,
        "intervals": {
            "(0, 1)": {
                "intercept": 0.01028132438659668,
                "slope": 0
            },
            "(1, 101)": {
                "intercept": 0.010153088569641113,
                "slope": 0.0001282358169555664
            },
            "(101, 201)": {
                "intercept": 0.018357961177825927,
                "slope": 4.6999454498291015e-05
            },
            "(201, 301)": {
                "intercept": -0.0010327720642089866,
                "slope": 0.00014347076416015625
            },
            "(301, 401)": {
                "intercept": 0.006368248462677001,
                "slope": 0.00011888265609741211
            },
            "(401, 501)": {
                "intercept": 0.030681772232055666,
                "slope": 5.825042724609375e-05
            },
            "(501, 601)": {
                "intercept": -0.023080446720123285,
                "slope": 0.000165560245513916
            },
            "(601, 701)": {
                "intercept": -0.00916273117065429,
                "slope": 0.00014240264892578124
            },
            "(701, 801)": {
                "intercept": -0.03169204711914064,
                "slope": 0.00017454147338867188
            },
            "(801, 901)": {
                "intercept": 0.035351033210754404,
                "slope": 9.084224700927734e-05
            },
            "(901, 1003)": {
                "intercept": 0.005571210384368905,
                "slope": 0.00012389421463012695
            }
        },
        "max_model_len": 2048,
        "max_num_batched_tokens": 1024,
        "max_num_seqs": 1003,
        "model": "neuralmagic/Meta-Llama-3-8B-Instruct-FP8",
        "model_name": "llama-8b_L40S",
        "num_gpu_blocks": 31471,
        "num_watermark_blocks": 314,
        "uses_cuda": true
    },
    "input_token_upper_limit": 1024,
    "max_model_len": 2048,
    "max_num_batched_tokens": 1024,
    "max_num_seqs": 1003,
    "model": "neuralmagic/Meta-Llama-3-8B-Instruct-FP8",
    "model_name": "llama-8b_L40S",
    "no_cuda_profile": {
        "block_size": 16,
        "input_token_upper_limit": 1024,
        "intervals": {
            "(0, 1)": {
                "intercept": 0.011081457138061523,
                "slope": 0
            },
            "(1, 2)": {
                "intercept": -0.0015244483947753906,
                "slope": 0.012605905532836914
            },
            "(102, 152)": {
                "intercept": 0.02150578498840332,
                "slope": -7.009506225585937e-06
            },
            "(152, 202)": {
                "intercept": 0.016470651626586914,
                "slope": 2.6116371154785158e-05
            },
            "(2, 52)": {
                "intercept": 0.0236562442779541,
                "slope": 1.555919647216797e-05
            },
            "(202, 252)": {
                "intercept": 0.006999397277832033,
                "slope": 7.300376892089843e-05
            },
            "(252, 302)": {
                "intercept": 0.0019237136840820311,
                "slope": 9.314537048339844e-05
            },
            "(302, 352)": {
                "intercept": -0.10340861320495603,
                "slope": 0.0004419279098510742
            },
            "(352, 402)": {
                "intercept": 0.16905186653137208,
                "slope": -0.0003321075439453125
            },
            "(402, 452)": {
                "intercept": 0.02166638374328613,
                "slope": 3.452301025390625e-05
            },
            "(452, 502)": {
                "intercept": -0.012755975723266602,
                "slope": 0.00011067867279052735
            },
            "(502, 552)": {
                "intercept": -0.011978015899658204,
                "slope": 0.0001091289520263672
            },
            "(52, 102)": {
                "intercept": 0.028286809921264647,
                "slope": -7.349014282226563e-05
            },
            "(552, 602)": {
                "intercept": -0.016007823944091795,
                "slope": 0.00011642932891845703
            },
            "(602, 652)": {
                "intercept": 0.0649936294555664,
                "slope": -1.812458038330078e-05
            },
            "(652, 702)": {
                "intercept": -0.013909130096435546,
                "slope": 0.00010289192199707031
            },
            "(702, 752)": {
                "intercept": 0.05506732940673828,
                "slope": 4.634857177734375e-06
            },
            "(752, 802)": {
                "intercept": -0.2519932174682617,
                "slope": 0.00041296005249023436
            },
            "(802, 852)": {
                "intercept": 0.3434667873382568,
                "slope": -0.00032950878143310546
            },
            "(852, 902)": {
                "intercept": -0.021188783645629886,
                "slope": 9.849071502685547e-05
            },
            "(902, 952)": {
                "intercept": 0.0288111686706543,
                "slope": 4.3058395385742186e-05
            },
            "(952, 1024)": {
                "intercept": -0.03131437301635742,
                "slope": 0.0001062154769897461
            }
        },
        "max_model_len": 2048,
        "max_num_batched_tokens": 1024,
        "max_num_seqs": 1003,
        "model": "neuralmagic/Meta-Llama-3-8B-Instruct-FP8",
        "model_name": "llama-8b_L40S",
        "num_gpu_blocks": 31471,
        "num_watermark_blocks": 314,
        "uses_cuda": false
    },
    "num_gpu_blocks": 31471,
    "num_watermark_blocks": 314
}