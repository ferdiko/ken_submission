{
    "block_size": 16,
    "cuda_profile": {
        "block_size": 16,
        "input_token_upper_limit": 1024,
        "intervals": {
            "(0, 1)": {
                "intercept": 0.06716728210449219,
                "slope": 0
            },
            "(1, 69)": {
                "intercept": 0.06684692817575791,
                "slope": 0.0003203539287342745
            },
            "(101, 169)": {
                "intercept": 0.039617608575259936,
                "slope": 0.000558923272525563
            },
            "(169, 185)": {
                "intercept": 0.09192943572998047,
                "slope": 0.0002493858337402344
            },
            "(185, 201)": {
                "intercept": 0.09014308452606201,
                "slope": 0.00025904178619384766
            },
            "(201, 285)": {
                "intercept": 0.047478692872183675,
                "slope": 0.0004713024411882673
            },
            "(285, 301)": {
                "intercept": 0.12901602685451508,
                "slope": 0.00018520653247833252
            },
            "(301, 385)": {
                "intercept": 0.04716684420903525,
                "slope": 0.0004571307273138137
            },
            "(385, 401)": {
                "intercept": 0.1077347993850708,
                "slope": 0.00029981136322021484
            },
            "(401, 1024)": {
                "intercept": 0.1650696277618408,
                "slope": 0.0001568317413330078
            },
            "(69, 85)": {
                "intercept": 0.07433576881885529,
                "slope": 0.00021182000637054443
            },
            "(85, 101)": {
                "intercept": 0.07253339886665344,
                "slope": 0.00023302435874938965
            }
        },
        "max_model_len": 6700,
        "max_num_batched_tokens": 1024,
        "max_num_seqs": 1024,
        "model": "neuralmagic/Meta-Llama-3-70B-Instruct-FP8",
        "model_name": "llama70b_fp8",
        "num_gpu_blocks": 420,
        "num_watermark_blocks": 4,
        "uses_cuda": true
    },
    "input_token_upper_limit": 1024,
    "max_model_len": 6700,
    "max_num_batched_tokens": 1024,
    "max_num_seqs": 1024,
    "model": "neuralmagic/Meta-Llama-3-70B-Instruct-FP8",
    "model_name": "llama70b_fp8",
    "no_cuda_profile": {
        "block_size": 16,
        "input_token_upper_limit": 1024,
        "intervals": {
            "(0, 1)": {
                "intercept": 0.06739974021911621,
                "slope": 0
            },
            "(1, 2)": {
                "intercept": 0.06734943389892578,
                "slope": 5.030632019042969e-05
            },
            "(102, 152)": {
                "intercept": 0.03245428085327148,
                "slope": 0.0005708789825439453
            },
            "(152, 202)": {
                "intercept": 0.09424646377563477,
                "slope": 0.0001643514633178711
            },
            "(2, 52)": {
                "intercept": 0.06704623222351075,
                "slope": 0.00020190715789794922
            },
            "(202, 252)": {
                "intercept": 0.09452868461608888,
                "slope": 0.00016295433044433594
            },
            "(252, 302)": {
                "intercept": -0.14008589744567873,
                "slope": 0.0010939645767211914
            },
            "(302, 352)": {
                "intercept": 0.29873855590820314,
                "slope": -0.0003590965270996094
            },
            "(352, 402)": {
                "intercept": -0.001331024169921896,
                "slope": 0.0004933738708496094
            },
            "(402, 452)": {
                "intercept": 0.12187294960021973,
                "slope": 0.00018689632415771484
            },
            "(452, 502)": {
                "intercept": 0.13081530570983887,
                "slope": 0.00016711235046386718
            },
            "(502, 552)": {
                "intercept": -0.2749661445617676,
                "slope": 0.0009754419326782227
            },
            "(52, 102)": {
                "intercept": 0.0638813304901123,
                "slope": 0.0002627706527709961
            },
            "(552, 602)": {
                "intercept": 0.1528067970275879,
                "slope": 0.00020049095153808593
            },
            "(602, 652)": {
                "intercept": -0.013671312332153296,
                "slope": 0.00047703266143798827
            },
            "(652, 702)": {
                "intercept": -0.00911665916442872,
                "slope": 0.0004700469970703125
            },
            "(702, 752)": {
                "intercept": 0.4066099452972412,
                "slope": -0.00012215614318847657
            },
            "(752, 802)": {
                "intercept": -0.37945816993713377,
                "slope": 0.000923147201538086
            },
            "(802, 852)": {
                "intercept": 0.21062496185302734,
                "slope": 0.00018738269805908204
            },
            "(852, 902)": {
                "intercept": 0.01120153427124021,
                "slope": 0.00042144775390625
            },
            "(902, 952)": {
                "intercept": 0.23136046409606933,
                "slope": 0.00017736911773681642
            },
            "(952, 1024)": {
                "intercept": 0.2340932369232178,
                "slope": 0.0001744985580444336
            }
        },
        "max_model_len": 6700,
        "max_num_batched_tokens": 1024,
        "max_num_seqs": 1024,
        "model": "neuralmagic/Meta-Llama-3-70B-Instruct-FP8",
        "model_name": "llama70b_fp8",
        "num_gpu_blocks": 420,
        "num_watermark_blocks": 4,
        "uses_cuda": false
    },
    "num_gpu_blocks": 420,
    "num_watermark_blocks": 4
}