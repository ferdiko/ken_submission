{
    "block_size": 16,
    "cuda_profile": {
        "block_size": 16,
        "input_token_upper_limit": 512,
        "intervals": {
            "(0, 1)": {
                "intercept": 0.0668635368347168,
                "slope": 0
            },
            "(1, 5)": {
                "intercept": 0.06649953126907349,
                "slope": 0.00036400556564331055
            },
            "(101, 117)": {
                "intercept": 0.08076952397823334,
                "slope": 0.00015206634998321533
            },
            "(117, 145)": {
                "intercept": -0.02867765086037774,
                "slope": 0.001087512288774763
            },
            "(145, 201)": {
                "intercept": 0.09494344677243914,
                "slope": 0.0002349529947553362
            },
            "(17, 21)": {
                "intercept": 0.06996619701385498,
                "slope": 0.00012004375457763672
            },
            "(201, 245)": {
                "intercept": 0.1106972260908647,
                "slope": 0.0001565759832208807
            },
            "(21, 45)": {
                "intercept": 0.06635358929634094,
                "slope": 0.00029207269350687665
            },
            "(245, 301)": {
                "intercept": 0.00017204880714416504,
                "slope": 0.0006076991558074951
            },
            "(301, 401)": {
                "intercept": 0.061464598178863517,
                "slope": 0.0004040694236755371
            },
            "(401, 512)": {
                "intercept": 0.13567768335342406,
                "slope": 0.00021899938583374022
            },
            "(45, 53)": {
                "intercept": 0.0767449140548706,
                "slope": 6.115436553955078e-05
            },
            "(5, 17)": {
                "intercept": 0.06678315003712972,
                "slope": 0.0003072818120320638
            },
            "(53, 101)": {
                "intercept": 0.062162493666013084,
                "slope": 0.00033629437287648517
            }
        },
        "max_model_len": 6700,
        "max_num_batched_tokens": 512,
        "max_num_seqs": 512,
        "model": "neuralmagic/Meta-Llama-3-70B-Instruct-FP8",
        "model_name": "llama70b_fp8",
        "num_gpu_blocks": 1375,
        "num_watermark_blocks": 13,
        "uses_cuda": true
    },
    "input_token_upper_limit": 512,
    "max_model_len": 6700,
    "max_num_batched_tokens": 512,
    "max_num_seqs": 512,
    "model": "neuralmagic/Meta-Llama-3-70B-Instruct-FP8",
    "model_name": "llama70b_fp8",
    "no_cuda_profile": {
        "block_size": 16,
        "input_token_upper_limit": 512,
        "intervals": {
            "(0, 1)": {
                "intercept": 0.06723880767822266,
                "slope": 0
            },
            "(1, 2)": {
                "intercept": 0.06518793106079102,
                "slope": 0.0020508766174316406
            },
            "(102, 152)": {
                "intercept": 0.03176135063171387,
                "slope": 0.0005858230590820312
            },
            "(152, 202)": {
                "intercept": 0.09618815422058105,
                "slope": 0.00016196250915527345
            },
            "(2, 52)": {
                "intercept": 0.06889894485473633,
                "slope": 0.0001953697204589844
            },
            "(202, 252)": {
                "intercept": 0.09508913040161132,
                "slope": 0.0001674032211303711
            },
            "(252, 302)": {
                "intercept": -0.047008380889892565,
                "slope": 0.0007312822341918945
            },
            "(302, 352)": {
                "intercept": 0.0043278980255127,
                "slope": 0.0005612945556640624
            },
            "(352, 402)": {
                "intercept": 0.24392903327941895,
                "slope": -0.00011939048767089844
            },
            "(402, 452)": {
                "intercept": 0.12163749694824219,
                "slope": 0.0001848173141479492
            },
            "(452, 512)": {
                "intercept": 0.12022792816162109,
                "slope": 0.00018793582916259765
            },
            "(52, 102)": {
                "intercept": 0.06610275268554687,
                "slope": 0.0002491426467895508
            }
        },
        "max_model_len": 6700,
        "max_num_batched_tokens": 512,
        "max_num_seqs": 512,
        "model": "neuralmagic/Meta-Llama-3-70B-Instruct-FP8",
        "model_name": "llama70b_fp8",
        "num_gpu_blocks": 1375,
        "num_watermark_blocks": 13,
        "uses_cuda": false
    },
    "num_gpu_blocks": 1375,
    "num_watermark_blocks": 13
}